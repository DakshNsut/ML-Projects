{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EXtdmfdFbdUL"},"outputs":[],"source":["def perform_basic_tasks():\n","  import langchain\n","  import openai\n","\n","  from sec import OpenAIkey\n","  key = OpenAIkey\n","\n","  from langchain.chat_models import AzureChatOpenAI\n","  from langchain.prompts import PromptTemplate\n","  from langchain.chains import LLMChain\n","  global llm\n","  llm = AzureChatOpenAI(azure_endpoint= 'https://amazebotopenai.openai.azure.com/', api_key = key, deployment_name= 'Chat', api_version='2023-05-15')\n","perform_basic_tasks()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esoL6ZP6gbEH","outputId":"ac76ea1a-90af-4eba-fa4d-67d72cfe167a"},"outputs":[{"name":"stdout","output_type":"stream","text":["London\n"]}],"source":["output = llm.predict('What is the capital of England?')\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bPW1r430q4I"},"outputs":[],"source":["prompt = PromptTemplate.from_template(\"What is the capital of {place}?\")\n","chain1 = LLMChain(llm=llm, prompt=prompt)\n","\n","prompt = PromptTemplate.from_template(\"What are the famous food of {capital}\")\n","chain2 = LLMChain(llm=llm, prompt=prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBZ0VqtQXa2Q","outputId":"d96bb5be-21a8-42c0-b0b7-7bcef411ae17"},"outputs":[{"name":"stdout","output_type":"stream","text":["The famous food of New Delhi includes:\n","\n","1. Butter Chicken\n","2. Chole Bhature\n","3. Parathas\n","4. Kebabs\n","5. Biryani\n","6. Chaat\n","7. Samosas\n","8. Dosa\n","9. Golgappas\n","10. Kulfi Faluda\n","11. Rabri Falooda\n","12. Lassi\n","13. Aloo Tikki\n","14. Rajma Chawal\n","15. Nihari.\n"]}],"source":["from langchain.chains import SimpleSequentialChain\n","chain = SimpleSequentialChain(chains = [chain1, chain2])\n","output = chain.run('India')\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlMy4Ob4ceUU"},"outputs":[],"source":["# This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n","synopsis_template = \"\"\"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\n","\n","Title: {title}\n","Era: {era}\n","Playwright: This is a synopsis for the above play:\"\"\"\n","synopsis_prompt_template = PromptTemplate(\n","    input_variables=[\"title\", \"era\"], template=synopsis_template\n",")\n","synopsis_chain = LLMChain(\n","    llm=llm, prompt=synopsis_prompt_template, output_key=\"synopsis\"\n",")\n","\n","# This is an LLMChain to write a review of a play given a synopsis.\n","template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n","\n","Play Synopsis:\n","{synopsis}\n","Review from a New York Times play critic of the above play:\"\"\"\n","prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n","review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")\n","\n","# This is the overall chain where we run these two chains in sequence.\n","from langchain.chains import SequentialChain\n","\n","overall_chain = SequentialChain(\n","    chains=[synopsis_chain],\n","    input_variables=[\"era\", \"title\"],\n","    # Here we return multiple variables\n","    output_variables=[\"synopsis\", \"review\"],\n","    verbose=True,\n",")\n","\n","output = overall_chain({\"title\": \"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IcxzQd9QhJ3P","outputId":"d6eef0bc-4119-42b1-febb-d05e3ae8e94c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Using a calculator, 13 raised to the power of 0.3432 is approximately 2.272.'"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["llm.predict(\"What is 13 raised to the .3432 power ?\")"]},{"cell_type":"markdown","metadata":{"id":"d4vAf65AumNa"},"source":["**Agent tools to solve complex math and science questions**\n","https://vteam.ai/blog/posts/mathematics-using-ll-ms-and-langchain<br>\n","https://github.com/gkamradt/langchain-tutorials/blob/main/agents/Agents.ipynb<br>\n","**How to provide knowledge base to the agent(RAG, Retrieval Question Answering langchain)**\n","1. https://www.youtube.com/watch?v=1towAoXOWLg\n","2. https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed\n","3. https://www.youtube.com/watch?app=desktop&v=iGZ0cV-SRLI\n","4. https://medium.com/@plbiojout/knowledge-based-agent-deployment-with-langchain-pinecone-and-phospho-bf8dffd1026d\n","5. https://js.langchain.com/docs/use_cases/autonomous_agents/sales_gpt\n","6. https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"yvHWEA27ITqc","outputId":"9bdd5474-edb8-4443-bd12-0cee399ed191"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n","What is 13 raised to the .3432 power ?\u001b[32;1m\u001b[1;3m```text\n","13 ** 0.3432\n","```\n","...numexpr.evaluate(\"13 ** 0.3432\")...\n","\u001b[0m\n","Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Answer: 2.4116004626599237'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["from langchain import LLMMathChain\n","llm_math = LLMMathChain.from_llm(llm, verbose=True)\n","llm_math.run(\"What is 13 raised to the .3432 power ?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"1KKkzTT4SQwc","outputId":"4ec739ec-189b-4cf5-c0b6-2531fc376675"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new LLMSymbolicMathChain chain...\u001b[0m\n","What is the derivative of sin(x)*exp(x) with respect to x ?\u001b[32;1m\u001b[1;3m```text\n","diff(sin(x)*exp(x), x)\n","```\n","...sympy.sympify(\"diff(sin(x)*exp(x), x)\")...\n","\u001b[0m\n","Answer: \u001b[33;1m\u001b[1;3mexp(x)*sin(x) + exp(x)*cos(x)\u001b[0m\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Answer: exp(x)*sin(x) + exp(x)*cos(x)'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_experimental.llm_symbolic_math.base import LLMSymbolicMathChain\n","llm_symbolic_math = LLMSymbolicMathChain.from_llm(llm, verbose=True)\n","llm_symbolic_math.run(\"What is the derivative of sin(x)*exp(x) with respect to x ?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEs3yTjTTIe8"},"outputs":[],"source":["# llm_symbolic_math.run(\"x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"N1ACSBlOXpxZ","outputId":"095d519a-7da0-4dea-896a-0d5b1e0758f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new PALChain chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mdef solution():\n","    \"\"\"There is a group of 10 people who are ordering pizza. If each person gets 2 slices and each pizza has 4 slices, how many pizzas should they order?\"\"\"\n","    num_people = 10\n","    slices_per_person = 2\n","    slices_per_pizza = 4\n","    total_slices_needed = num_people * slices_per_person\n","    pizzas_needed = total_slices_needed // slices_per_pizza + (1 if total_slices_needed % slices_per_pizza != 0 else 0)\n","    result = pizzas_needed\n","    return result\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'5'"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_experimental.pal_chain import PALChain\n","pal_chain = PALChain.from_math_prompt(llm=llm, verbose=True)\n","pal_chain.run(\"There is a group of 10 people who are ordering pizza. If each person gets 2 slices and each pizza has 4 slices, how many pizzas should they order?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQMx2ED6ch3S"},"outputs":[],"source":["from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","python_repl = PythonREPL()\n","\n","python_repl = Tool(\n","    name=\"python_repl\",\n","    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n","    func=python_repl.run, handle_parsing_errors=True )\n","# handle_parsing_errors=True, is important. Without this it doesn't give correct answer\n","\n","pal_math = Tool(\n","    name=\"pal_math\",\n","    description=\"A LLM Chain which helps to solve word problems.\",\n","    func=pal_chain.run, handle_parsing_errors=True\n","  )\n","\n","# tools = load_tools(['llm-math', 'python_repl', 'wolfram-alpha', 'pal-math'], llm=llm)\n","tools = load_tools(['llm-math'], llm=llm)\n","tools.append(python_repl)\n","tools.append(pal_math)\n","\n","# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","\n","# agent.run(\"x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\")\n","# agent.run(\"x = y + 5, y = z - 3,  z = 5. Solve for x, y, z.\") # Ek baar mein sahi answer nahi deta, 3rd time run kar ke sahi answer diya.\n","# agent.run(\"There is a group of 10 people who are ordering pizza. If each person gets 2 slices and each pizza has 4 slices, how many pizzas should they order?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"hgs-sueI0o8B","outputId":"3cbb5ee8-3522-421c-9877-aedb5770df86"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThis is a system of equations, so we need to use substitution or elimination to solve for the variables.\n","Action: wolfram_alpha\n","Action Input: \"solve x = y + 5, y = z - 3, z = x * y\"\u001b[0m\n","Observation: \u001b[33;1m\u001b[1;3mAssumption: solve x = y + 5\n","y = z - 3\n","z = x y \n","Answer: x = 3 - sqrt(7) ∧ y = -2 - sqrt(7) ∧ z = 1 - sqrt(7)\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mWe have the solution for x, y, and z.\n","Final Answer: x = 3 - sqrt(7), y = -2 - sqrt(7), z = 1 - sqrt(7)\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'x = 3 - sqrt(7), y = -2 - sqrt(7), z = 1 - sqrt(7)'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["from sec import WolframAlphaKey\n","import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","# tools.append(python_repl)\n","# tools.append(pal_math)\n","agent = initialize_agent(tools, llm, agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","\n","agent.run(\"x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\") # Only Wolfram Alpha is able to give correct result for this question."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3EOphyhjl4nr","outputId":"9832b5e3-6439-4e4e-8ae7-9081a5a717f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThis is a system of equations that can be solved using substitution or elimination.\n","Action: pal_math\n","Action Input: \"Solve x = y + 5, y = z - 3, z = x * y\"\u001b[0m\n","\n","\u001b[1m> Entering new PALChain chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mdef solution():\n","    \"\"\"Solve x = y + 5, y = z - 3, z = x * y\"\"\"\n","    z = None  # we don't know the value of z yet\n","    y = z + 3  # from y = z - 3\n","    x = y + 5  # from x = y + 5\n","    z = x * y  # from z = x * y\n","    result = (x, y, z)\n","    return result\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","Observation: \u001b[38;5;200m\u001b[1;3mTypeError(\"unsupported operand type(s) for +: 'NoneType' and 'int'\")\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI need to input the equations in a different format. \n","Action: pal_math\n","Action Input: \"Solve the system of equations: x=y+5, y=z-3, z=x*y\"\u001b[0m\n","\n","\u001b[1m> Entering new PALChain chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mdef solution():\n","    \"\"\"Solve the system of equations: x=y+5, y=z-3, z=x*y\"\"\"\n","    # Rearrange the first equation to get y in terms of x\n","    # y = x - 5\n","    # Substitute this into the second equation to get z in terms of x\n","    # z = x*(x-5) + 3\n","    # Substitute this into the third equation to get x^2 - 5x - z + 3 = 0\n","    # Use the quadratic formula to solve for x\n","    a = 1\n","    b = -5\n","    c = -z + 3\n","    discriminant = b**2 - 4*a*c\n","    x = (-b + discriminant**0.5) / (2*a)\n","    # Use the first equation to solve for y\n","    y = x - 5\n","    # Use the second equation to solve for z\n","    z = y + 3\n","    result = (x, y, z)\n","    return result\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","Observation: \u001b[38;5;200m\u001b[1;3mUnboundLocalError(\"local variable 'z' referenced before assignment\")\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI need to rearrange the equations to avoid referencing variables before they are assigned.\n","Action: pal_math\n","Action Input: \"Solve the system of equations: x=y+5, z=y+3, y=x/(y+3)\"\u001b[0m\n","\n","\u001b[1m> Entering new PALChain chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mdef solution():\n","    \"\"\"Solve the system of equations: x=y+5, z=y+3, y=x/(y+3)\"\"\"\n","    # From the third equation:\n","    # y(y+3) = x\n","    # Substituting into the first equation:\n","    # x = y + 5\n","    # So we have:\n","    # y(y+3) = y + 5\n","    # y^2 + 3y = y + 5\n","    # y^2 + 2y - 5 = 0\n","    # Solving for y using the quadratic formula:\n","    a = 1\n","    b = 2\n","    c = -5\n","    y = (-b + ((b**2 - 4*a*c)**0.5))/(2*a)\n","    # Substituting back into the first equation to find x:\n","    x = y + 5\n","    # Substituting into the second equation to find z:\n","    z = y + 3\n","    result = (x, y, z)\n","    return result\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","Observation: \u001b[38;5;200m\u001b[1;3m(6.449489742783178, 1.4494897427831779, 4.449489742783178)\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mThe solutions are x = 6.45, y = 1.45, and z = 4.45.\n","Final Answer: x = 6.45, y = 1.45, z = 4.45.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'x = 6.45, y = 1.45, z = 4.45.'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","# tools.append(python_repl)\n","tools.append(pal_math)\n","agent = initialize_agent(tools, llm, agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","\n","agent.run(\"x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\") # Only Wolfram Alpha is able to give correct result for this question."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDxTQOiam0Qs"},"outputs":[],"source":["import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","tools.append(python_repl)\n","tools.append(pal_math)\n","agent = initialize_agent(tools, llm, agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, handle_parsing_errors=True)\n","\n","# Wolfram Alpha is not good for science questions\n","agent.run(\"Eight copper wire of length L and diameter D are joined in parallel to form a single composite conductor of resistance R. If a single copper wire of length 2L have the same resistance R then its diameter will be\")\n","# Unknown format\n","# agent.run(\"The total number of functions, f : {1, 2, 3, 4} → {1, 2, 3, 4, 5, 6} such that f(1) + f(2) = f(3), is equal to ?\")\n","# Iteration depth or limit reached\n","# agent.run(\"One end of a horizontal thick copper wire of length 2L and radius 2R is welded to an end of another horizontal thin copper wire of length L and radius R. When the arrangement is stretched by applying forces at two ends, the ratio of the elongation in the thin wire to that in the thick wire is\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xEmIzRVq4KN"},"outputs":[],"source":["# from langchain.chains import RetNWrite"]},{"cell_type":"markdown","metadata":{"id":"2AQ-B1_kl5mi"},"source":["# Loading the NCERT Textbook PDFs"]},{"cell_type":"markdown","metadata":{"id":"IaBgYyT4l5mj"},"source":["### Loading Chemistry Textbook to Vector DB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnp8GbExxki6"},"outputs":[],"source":["# https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed ( RAG )\n","from langchain.document_loaders import PyPDFLoader\n","\n","loaders = [\n","    PyPDFLoader(\"11Chemistry/Chapter 1.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 2.pdf\"),\n","]\n","\n","\n","docs = []\n","for loader in loaders:\n","    docs.extend(loader.load()) # loads each page as a list\n","# print(len(docs)) # len = total no. of pages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxFrZX5zl5mk","outputId":"3c7c61ed-7944-4e94-b034-15f6d63f5ca0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1320\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 1500,\n","    chunk_overlap = 150\n",")\n","\n","docs = text_splitter.split_documents(docs)\n","print(len(docs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bjfV0xCl5mk","outputId":"96d5af78-b60b-4334-caaf-cad7d4b608e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["191\n"]}],"source":["# # Convert Document object to text form. This preprocessing is needed to give it as an input to MiniLM embedding\n","# docs_text = []\n","\n","# for doc in docs:\n","#     text = doc.page_content\n","#     docs_text.append(text)\n","# print(len(docs_text))"]},{"cell_type":"markdown","metadata":{"id":"QpRueCe9l5ml"},"source":["# MiniLM Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_1a5sVWl5ml"},"outputs":[],"source":["# from sentence_transformers import SentenceTransformer\n","# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n","\n","# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","# embeddings = model.encode(sentences)\n","# print(len(embeddings[0]))\n","# print(embeddings[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"331vKOXBl5ml","outputId":"b4bc5591-83a7-4a7a-e992-6a37eb220a5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# doc_result = embedding.embed_documents(docs_text)\n","# doc_result = embedding.embed_texts(docs_text)\n","# print(len(doc_result[0]))"]},{"cell_type":"markdown","metadata":{"id":"QSk1oEISl5mm"},"source":["# Storing the embeddings in Vector DB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TY6boFM4l5mm","outputId":"15374d79-e4da-42aa-a31a-4da1393d2f80"},"outputs":[{"name":"stdout","output_type":"stream","text":["1320\n"]}],"source":["from langchain.vectorstores import Chroma\n","\n","# We save this vector store in a persistent directory so that we can use it in future.\n","persist_directory = 'docs/chemistry/chroma/'\n","\n","# Create the vector store\n","chemistryVectorDB = Chroma.from_documents(\n","    documents=docs,\n","    embedding=embedding,\n","    persist_directory=persist_directory\n",")\n","\n","print(chemistryVectorDB._collection.count())"]},{"cell_type":"markdown","metadata":{"id":"aMhzB_CGl5mm"},"source":["### Loading Chemistry, Math and Physics NCERT Textbook to Vector DB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Co38XEtdl5mn"},"outputs":[],"source":["from langchain.document_loaders import PyPDFLoader\n","loaders = [\n","    PyPDFLoader(\"11Chemistry/Chapter 1.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 2.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 3.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 4.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 5.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 6.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 7.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 8.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Chapter 9.pdf\"),\n","    PyPDFLoader(\"11Chemistry/Answers.pdf\"),\n","\n","    PyPDFLoader(\"12Chemistry/Chapter 1.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 2.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 3.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 4.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 5.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 6.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 7.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 8.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 9.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Chapter 10.pdf\"),\n","    PyPDFLoader(\"12Chemistry/Answer.pdf\"),\n","\n","    PyPDFLoader(\"11Maths/Ch 1.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 2.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 3.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 4.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 5.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 6.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 7.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 8.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 9.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 10.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 11.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 12.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 13.pdf\"),\n","    PyPDFLoader(\"11Maths/Ch 14.pdf\"),\n","    PyPDFLoader(\"11Maths/Answers.pdf\"),\n","\n","    PyPDFLoader(\"12Maths/Ch 1.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 2.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 3.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 4.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 5.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 6.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 7.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 8.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 9.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 10.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 11.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 12.pdf\"),\n","    PyPDFLoader(\"12Maths/Ch 13.pdf\"),\n","    PyPDFLoader(\"12Maths/Answers.pdf\"),\n","\n","    PyPDFLoader(\"11Physics/Chapter 1.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 2.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 3.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 4.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 5.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 6.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 7.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 8.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 9.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 10.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 11.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 12.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 13.pdf\"),\n","    PyPDFLoader(\"11Physics/Chapter 14.pdf\"),\n","    PyPDFLoader(\"11Physics/Solutions 1.pdf\"),\n","    PyPDFLoader(\"11Physics/Solutions 2.pdf\"),\n","\n","    PyPDFLoader(\"12Physics/Chapter 1.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 2.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 3.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 4.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 5.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 6.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 7.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 8.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 9.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 10.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 11.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 12.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 13.pdf\"),\n","    PyPDFLoader(\"12Physics/Chapter 14.pdf\"),\n","    PyPDFLoader(\"12Physics/Solutions.pdf\"),\n","]\n","\n","docs = []\n","for loader in loaders:\n","    docs.extend(loader.load())\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 1500,\n","    chunk_overlap = 150\n",")\n","\n","docs = text_splitter.split_documents(docs)\n","print(len(docs))\n","\n","from langchain.embeddings import HuggingFaceEmbeddings\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# Store the embeddings in VectorDB\n","from langchain.vectorstores import Chroma\n","\n","# We save this vector store in a persistent directory so that we can use it in future.\n","persist_directory = 'docs/chroma/'\n","\n","# Create the vector store\n","VectorDB = Chroma.from_documents(\n","    documents=docs,\n","    embedding=embedding,\n","    persist_directory=persist_directory\n",")\n","\n","print(VectorDB._collection.count())"]},{"cell_type":"markdown","metadata":{"id":"v0EymXv3l5mn"},"source":["https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed <br>\n","**Retrieval section in medium article above** <br>"]},{"cell_type":"markdown","metadata":{"id":"AxlJ1oyRl5mn"},"source":["# Retrieval from VectorDB (Chroma DB)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4fUDlU1l5mo"},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","\n","persist_directory = 'docs/chroma/'\n","vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n","\n","# Build prompt\n","template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n","{context}\n","Question: {question}\n","Helpful Answer:\"\"\"\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template) # Run chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever(),\n","    # return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Asy_TNAml5mo"},"outputs":[],"source":["from langchain.agents import Tool\n","retrieval_tool = Tool(\n","    name='RetrievalQA',\n","    description = 'This tool can be used to get context from the knowledge base of textbooks.',\n","    func=qa_chain.run, handle_parsing_errors=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4IOwrH8l5mo","outputId":"da391ccc-f8b3-444c-e7e3-4b90052b7d91"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to find the conversion formula for Fahrenheit to Celsius.\n","Action: RetrievalQA\n","Action Input: \"Fahrenheit to Celsius conversion formula\"\u001b[0m\n","Observation: \u001b[33;1m\u001b[1;3mThe Fahrenheit to Celsius conversion formula is: C = (F-32) x 5/9. Thanks for asking!\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mNow I need to input the values into the formula.\n","Action: Calculator\n","Action Input: (200-32) x 5/9\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mAnswer: 93.33333333333333\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n","Final Answer: The reading on the Celsius scale would be 93.33 °C.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'The reading on the Celsius scale would be 93.33 °C.'"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","tools = load_tools(['llm-math'], llm=llm)\n","tools.append(retrieval_tool)\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, handle_parsing_errors=True)\n","# agent.run(\"Given equations for variable x, y, and z: x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\")\n","agent.run(\"Use 'retrieval_tool' to answer the following - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzknjouFl5mp","outputId":"caf21942-093d-4052-9836-fd83de5d2b1d"},"outputs":[{"data":{"text/plain":["{'query': 'Use retrieval_tool to answer the following, also tell which document help to provide the context - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?',\n"," 'result': 'The temperatures on the Fahrenheit scale are represented between 32° to 212°. The Celsius scale is calibrated from 0° to 100°, where these two temperatures are the freezing point and the boiling point of water, respectively. The temperatures on two scales are related to each other by the following relationship: °C = (°F - 32) × 5/9. Therefore, the temperature on the Celsius scale would be 93.3 °C if the measured temperature on the Fahrenheit scale is 200 °F. Thanks for asking! \\n\\nContext document: 1.4 Uncertainty in measurement',\n"," 'source_documents': [Document(page_content='10\\nchemistry\\nIn the laboratory, the volume of liquids \\nor solutions can be measured by graduated \\ncylinder, burette, pipette, etc. A volumetric flask  is used to prepare a known volume of a solution. These measuring devices are shown in Fig. 1.7.\\n Fig. 1.7  Some volume measuring devices\\n1.4 Uncertainty in meaSUrement\\nMany a time in \\nthe study of chemistry, one \\nhas to deal with experimental data as well as theoretical calculations. There are meaningful ways to handle the numbers conveniently and fahrenheit) and K (kelvin). Here, K is the \\nSI unit. The thermometers based on these scales are shown in Fig. 1.8. Generally, the thermometer with celsius scale are calibrated from 0° to 100°, where these two temperatures are the freezing point and the boiling point of water, respectively. The fahrenheit scale is represented between 32° to 212°. \\nThe temperatures on two scales are \\nrelated to each other by the following relationship:\\n/unif0b0/unif03d /unif0b0/unif02b/unif028/unif029 FC9\\n532 \\nThe kelvin scale is related to celsius scale \\nas follows:\\nK = °C + 273.15\\nIt is interesting to note that temperature \\nbelow 0 °C (i.e., negative values) are possible \\nin Celsius scale but in Kelvin scale, negative temperature is not possible.\\nFig. 1.8  Thermometers using different \\ntemperature scales1.3.6  Density\\nThe two properties — mass and volume \\ndiscussed above are related as follows:\\n=MassDensityVolume\\nDensity of a substance is its amount of mass', metadata={'page': 9, 'source': '11Chemistry/Chapter 1.pdf'}),\n","  Document(page_content='Thus, we can write 232.508 as  \\n2.32508 ×\\n 102 in scientific notation. Note that \\nwhile writing it, the decimal had to be moved to the left by two places and same is the exponent (2) of 10 in the scientific notation.\\nSimilarly, 0.00016 can be written as  \\n1.6 ×\\n 10–4. Here, the decimal has to be \\nmoved four places to the right and (–4) is the exponent in the scientific notation.\\nWhile performing mathematical operations \\non numbers expressed in scientific notations, the following points are to be kept in mind.reference Standard\\nAfter defining a unit of measurement such as \\nthe kilogram or the metre, scientists agreed on reference standards that make it possible to calibrate all measuring devices. For getting reliable measurements, all devices such as metre sticks and analytical balances have been calibrated by their manufacturers to give correct readings. However, each of these devices is standardised or calibrated against some reference. The mass standard is the kilogram since 1889. It has been defined as the mass of platinum-iridium (Pt-Ir) cylinder that is stored in an airtight jar at International Bureau of Weights and Measures in Sevres, France. Pt-Ir was chosen for this standard because it is highly resistant to chemical attack and its mass will not change for an extremely long time. \\nScientists are in search of a new', metadata={'page': 10, 'source': '11Chemistry/Chapter 1.pdf'}),\n","  Document(page_content='values with suitable units. \\nUnit 1.indd   3 9/9/2022   4:27:29 PM\\nRationalised 2023-24', metadata={'page': 2, 'source': '11Chemistry/Chapter 1.pdf'}),\n","  Document(page_content='12\\nchemistry\\nMultiplication and Division\\nThese two operations follow the same rules \\nwhich are there for exponential numbers, i.e.mass obtained by an analytical balance is \\nslightly higher than the mass obtained by using a platform balance. Therefore, digit 4 placed after decimal in the measurement by platform balance is uncertain. \\nThe uncertainty in the experimental \\nor the calculated values is indicated by mentioning the number of significant figures. Significant\\n\\tfigures are meaningful \\ndigits which are known with certainty plus one which \\nis estimated or uncertain. The \\nuncertainty is indicated by writing the certain digits and the last uncertain digit. Thus, if we write a result as 11.2 mL, we say the 11 is certain and 2 is uncertain and the uncertainty would be +1 in the last digit. Unless otherwise \\nstated, an uncertainty of +1 in the last digit is always understood. \\nThere are certain rules for determining \\nthe number of significant figures. These are stated below:(1)\\n All non-zero digits are significant. \\nFor \\nexample in 285 cm, there are three significant figures and in 0.25 mL, there are two significant figures.\\n(2)\\n Zeros preceding to first non-zero \\ndigit \\nare not significant. Such zero indicates the position of decimal point. Thus, 0.03 has one significant figure and 0.0052 has two significant figures.\\n(3)\\n Zeros between two non-zero digits are significant. Thus, \\n2.005 has four \\nsignificant figures.\\n(4) Zeros at the end or \\nright of a number', metadata={'page': 11, 'source': '11Chemistry/Chapter 1.pdf'})]}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["question = 'Use retrieval_tool to answer the following, also tell which document help to provide the context - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?'\n","result = qa_chain({\"query\": question})\n","result"]},{"cell_type":"markdown","metadata":{"id":"ZPSNwyoSl5mp"},"source":["**Chain-of-Thought and Self-Correction** <br>\n","1) https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models#:~:text=Prompt%20engineering%20has%20emerged%20as,saving%20both%20time%20and%20resources.\n","2) https://medium.com/@johannes.koeppern/self-consistency-with-chain-of-thought-cot-sc-2f7a1ea9f941\n","3) https://www.youtube.com/watch?v=SvbK-zO9nzQ\n","4) https://www.youtube.com/watch?v=gnHOqjfOAsQ\n","\n","**Gemini-Pro-AI API**:\n","1) https://www.youtube.com/watch?v=NHt_Th2rgvQ <br>\n","2) https://www.youtube.com/watch?v=f6ZmtKvPni4 <br>\n","3) https://www.youtube.com/watch?v=ZrH3yW2beVs <br>\n","4) https://www.youtube.com/watch?v=G3-YOEVg-xc <br>\n","5) https://python.langchain.com/docs/integrations/chat/google_generative_ai <br>\n","6) https://www.analyticsvidhya.com/blog/2023/12/google-gemini-api/#:~:text=Langchain%20and%20Gemini%20Integration,-With%20the%20release&text=First%2C%20we%20create%20the%20llm,function%20will%20generate%20the%20response. <br>"]},{"cell_type":"markdown","metadata":{"id":"RRJ0ugRMl5mq"},"source":["# Working with Gemini Pro API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRVsvZvNl5mq","outputId":"6702ae8e-ce26-49bb-c038-045686229d0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["93.33\n"]}],"source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","from sec import GeminiKey\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GeminiKey)\n","# result = llm.invoke(\"Equations for x, y, and z are given: x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z. Return only final values of x, y, z and not the steps using which you reached there.\")\n","result = llm.invoke(\"The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale? Return only final decimal value upto 2 decimal places and not the steps using which you reached there.\")\n","print(result.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6x_pRF60l5mq"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate\n","# template = '''Answer the question as based only on the following context:\n","# {context}\n","# Question: {question}\n","# '''\n","\n","template = '''Answer the question use the following context if needed:\n","{context}\n","Question: {question}\n","'''\n","\n","prompt = ChatPromptTemplate.from_template(template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnFjX3rzl5mq","outputId":"61fb2625-cb35-4bb7-a00b-c0d1c370c956"},"outputs":[{"name":"stdout","output_type":"stream","text":["93.3\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# Defining vectordb\n","from langchain.vectorstores import Chroma\n","persist_directory = 'docs/chroma/'\n","vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n","\n","document_content_description = \"Brief summary of a chemistry text\"\n","from langchain.retrievers.self_query.base import SelfQueryRetriever\n","retriever = SelfQueryRetriever.from_llm(\n","    llm, vectordb, document_content_description, metadata_field_info =[], verbose=True\n",")\n","\n","# output parser\n","from langchain.schema.output_parser import StrOutputParser\n","output_parser = StrOutputParser()\n","\n","from langchain.schema.runnable import RunnableMap\n","chain = RunnableMap({\n","    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n","    \"question\": lambda x: x[\"question\"]\n","}) | prompt | llm | output_parser\n","\n","result = chain.invoke({\"question\": \"The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale? Return only final decimal value and not the steps using which you reached there. \"})\n","# result = chain.invoke({\"question\": \"The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale? \"})\n","print(result)\n","# print(result.content) -> This is not needed when you use output_parser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPmFgkSll5mx","outputId":"42253a74-648c-470e-8951-cc6dd8d01754"},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n","8\n"]}],"source":["results = llm.batch(\n","    [\n","        \"What's 2+2?\",\n","        \"What's 3+5?\",\n","    ]\n",")\n","for res in results:\n","    print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"nChHJiBNl5mx"},"source":["# Final OpenAI API Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6UZn7rC5l5my"},"outputs":[],"source":["import langchain\n","import openai\n","\n","# from langchain_google_genai import ChatGoogleGenerativeAI\n","# from sec import GeminiKey\n","# llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GeminiKey)\n","\n","from sec import OpenAIkey, WolframAlphaKey\n","key = OpenAIkey\n","\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","llm = AzureChatOpenAI(azure_endpoint= 'https://amazebotopenai.openai.azure.com/', api_key = key, deployment_name= 'Chat', api_version='2023-05-15')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUPOgV5el5my"},"outputs":[],"source":["query_template = '''Solve this question:\n","{Question}\\n and return the correct option number\\n\n","(1) {Option_1}\\n\n","(2) {Option_2}\\n\n","(3) {Option_3}\\n\n","(4) {Option_4}\\n\n","Output the correct option number (1, 2, 3, or 4). I want the output to not exceed length 1.\n","A quick tip: Use wolfram-alpha tool provided to solve math questions. This tool is good for math.\n","Use retrieval_tool to extract context from knowledge base.\n","Let's think step-by-step to reach the final answer.'''\n","\n","query_template = PromptTemplate(\n","    input_variables=[\"Question\", \"Option_1\", \"Option_2\", \"Option_3\", \"Option_4\"],\n","    template=query_template\n",")\n","\n","chain = LLMChain(llm=llm, prompt=query_template, output_key=\"correct_option\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_idL_hr1l5my","outputId":"408a2612-ccd9-4b90-bf4a-457b9614eb61"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","from langchain_experimental.pal_chain import PALChain\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","python_repl = PythonREPL()\n","pal_chain = PALChain.from_math_prompt(llm=llm)\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","persist_directory = 'docs/chroma/'\n","vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever(),\n",")\n","\n","python_repl = Tool(\n","    name=\"python_repl\",\n","    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n","    func=python_repl.run, handle_parsing_errors=True\n",")\n","\n","pal_math = Tool(\n","    name=\"pal_math\",\n","    description=\"A LLM Chain which helps to solve word problems.\",\n","    func=pal_chain.run, handle_parsing_errors=True\n",")\n","\n","retrieval_tool = Tool(\n","    name='RetrievalQA',\n","    description = 'This tool can be used to get context from the knowledge base of textbooks.',\n","    func=qa_chain.run, handle_parsing_errors=True\n",")\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","tools.append(python_repl)\n","tools.append(pal_math)\n","tools.append(retrieval_tool)\n","\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True)\n","# agent.run(\"Given equations for variable x, y, and z: x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\")\n","# agent({question:\"Use 'retrieval_tool' to answer the following - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?\"})\n","# agent.run(\"Use 'retrieval_tool' to answer the following - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRFP3f8xl5mz"},"outputs":[],"source":["import pandas as pd\n","from pylatexenc.latex2text import LatexNodes2Text\n","data = pd.read_csv('2013_Paper1 - MCQS.csv')\n","data = data.head(5)\n","\n","def latex_to_text(i):\n","    data.loc[i, 'Question'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Question'])\n","    data.loc[i, 'Option1'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option1'])\n","    data.loc[i, 'Option2'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option2'])\n","    data.loc[i, 'Option3'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option3'])\n","    data.loc[i, 'Option4'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option4'])\n","\n","def predict(i):\n","    try:\n","        query_template.format(Option_1=data.loc[i, 'Option1'], Option_2=data.loc[i, 'Option2'], Option_3=data.loc[i, 'Option3'], Option_4=data.loc[i, 'Option4'], Question=data.loc[i, 'Question'])\n","        result = agent.invoke(query_template)\n","    except:\n","        return 'Error'\n","    else:\n","        return result['output']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-u_N6Q5l5mz","outputId":"03588dfd-ea41-4268-9412-f7c274c2a2d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Agent stopped due to iteration limit or time limit.\n","(1)\n","1\n","1\n","0\n"]}],"source":["score = 0 # 1 for each correct answer\n","for i in range(1):\n","    latex_to_text(i)\n","    pred = predict(i)\n","    print(pred)\n","    while(pred == 'Error' or len(pred) > 1):\n","        pred = predict(i)\n","        print(pred)\n","    pred = int(pred)\n","    print(pred)\n","    if pred == 1:\n","        if data['Answer1'][i] == 1:\n","            score+=1\n","    elif pred == 2:\n","        if data['Answer2'][i] == 1:\n","            score+=1\n","    elif pred == 3:\n","        if data['Answer3'][i] == 1:\n","            score+=1\n","    elif pred == 4:\n","        if data['Answer4'][i] == 1:\n","            score+=1\n","print(score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlf0hiyvl5mz","outputId":"7026cf6e-1cce-4e24-b18f-577685005287"},"outputs":[{"name":"stderr","output_type":"stream","text":["Python REPL can execute arbitrary code. Use with caution.\n","Python REPL can execute arbitrary code. Use with caution.\n"]},{"name":"stdout","output_type":"stream","text":["1:15\n","Error\n","Option B (2)\n","Error\n","Agent stopped due to iteration limit or time limit.\n","12\n","Error\n","2\n","2\n","0\n"]}],"source":["score = 0 # 1 for each correct answer\n","for i in range(1): # 1 should be replaced with len(data)\n","    latex_to_text(i)\n","    while(1):\n","        pred = predict(i)\n","        if pred == 'Error' or len(pred) > 1:\n","            print(pred)\n","            pred = predict(i)\n","        else:\n","            break\n","    pred = int(pred)\n","    print(pred)\n","    if pred == 1:\n","        if data['Answer1'][i] == 1:\n","            score+=1\n","    elif pred == 2:\n","        if data['Answer2'][i] == 1:\n","            score+=1\n","    elif pred == 3:\n","        if data['Answer3'][i] == 1:\n","            score+=1\n","    elif pred == 4:\n","        if data['Answer4'][i] == 1:\n","            score+=1\n","print(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypzZx3btl5m0","outputId":"899c9f1a-b6e0-457c-f33e-7b9026769f11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error\n","The value of x in the equation 2x + 5 = 13 is (1) 4.\n","3\n","3\n","Error\n","Option 2\n","Error\n"]},{"name":"stderr","output_type":"stream","text":["Python REPL can execute arbitrary code. Use with caution.\n"]},{"name":"stdout","output_type":"stream","text":["40\n","Option_3\n","Error\n","N/A\n","Error\n","Error\n","Error\n","20.0\n","Error\n","(3) Option_3\n","Agent stopped due to iteration limit or time limit.\n","Error\n","Error\n","Agent stopped due to iteration limit or time limit.\n","3\n","3\n","Agent stopped due to iteration limit or time limit.\n","3\n","3\n","The probability of rolling a 6 on a fair dice is 1/6.\n","2\n","2\n","1\n"]}],"source":["# Implementing self-consistency with CoT\n","from statistics import mode\n","\n","def evaluate(pred, score, i):\n","    if pred == 1:\n","        if data['Answer1'][i] == 1:\n","            score+=1\n","    elif pred == 2:\n","        if data['Answer2'][i] == 1:\n","            score+=1\n","    elif pred == 3:\n","        if data['Answer3'][i] == 1:\n","            score+=1\n","    elif pred == 4:\n","        if data['Answer4'][i] == 1:\n","            score+=1\n","    return score\n","\n","def solve(i):\n","    pred = predict(i)\n","    print(pred)\n","    while(pred == 'Error' or len(pred) > 1):\n","        pred = predict(i)\n","        print(pred)\n","    pred = int(pred)\n","    print(pred)\n","    return pred\n","\n","score = 0\n","for i in range(1): # 1 should be replaced with len(data)\n","    latex_to_text(i)\n","    responses = []\n","    for iter in range(4):\n","        responses.append(solve(i))\n","    final_pred = mode(responses)\n","    score = evaluate(final_pred, score, i)\n","print(score)\n","\n","# In the output below we can see that there are many time we see some Errors. Such errors are ignored and the llm is called again to get the actual answer.\n","# The output as '3' or '2' is the option number selected. Output as 'Option 2' or 'Option_3' or '(3) Option_3' is ignored.\n","# We see the responses we get are [3,3,3,2]. Mode=3 which is the final answer.\n","# Self-Consistency helps to select the correct option."]},{"cell_type":"markdown","metadata":{"id":"dUNuKvEul5m0"},"source":["# Final GeminiPro API Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLFmq4vIl5m0"},"outputs":[],"source":["import langchain\n","import openai\n","\n","from sec import OpenAIkey, WolframAlphaKey\n","key = OpenAIkey\n","\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from sec import GeminiKey\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GeminiKey)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wI-CSj3ol5m0"},"outputs":[],"source":["query_template = '''Solve this question:\n","{Question}\\n and return the correct option number\\n\n","(1) {Option_1}\\n\n","(2) {Option_2}\\n\n","(3) {Option_3}\\n\n","(4) {Option_4}\\n\n","Output the correct option number (1, 2, 3, or 4). I want the output to not exceed length 1.\n","A quick tip: Use wolfram-alpha tool provided to solve math questions. This tool is good for math.\n","Use retrieval_tool to extract context from knowledge base.\n","Let's think step-by-step to reach the final answer.'''\n","\n","query_template = PromptTemplate(\n","    input_variables=[\"Question\", \"Option_1\", \"Option_2\", \"Option_3\", \"Option_4\"],\n","    template=query_template\n",")\n","\n","chain = LLMChain(llm=llm, prompt=query_template, output_key=\"correct_option\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clzCxYV7l5m1"},"outputs":[],"source":["from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","from langchain_experimental.pal_chain import PALChain\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","python_repl = PythonREPL()\n","pal_chain = PALChain.from_math_prompt(llm=llm)\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","persist_directory = 'docs/chroma/'\n","vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever(),\n",")\n","\n","python_repl = Tool(\n","    name=\"python_repl\",\n","    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n","    func=python_repl.run, handle_parsing_errors=True\n",")\n","\n","pal_math = Tool(\n","    name=\"pal_math\",\n","    description=\"A LLM Chain which helps to solve word problems.\",\n","    func=pal_chain.run, handle_parsing_errors=True\n",")\n","\n","retrieval_tool = Tool(\n","    name='RetrievalQA',\n","    description = 'This tool can be used to get context from the knowledge base of textbooks.',\n","    func=qa_chain.run, handle_parsing_errors=True\n",")\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","tools.append(python_repl)\n","tools.append(pal_math)\n","tools.append(retrieval_tool)\n","\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYbkRGljl5m1"},"outputs":[],"source":["import pandas as pd\n","from pylatexenc.latex2text import LatexNodes2Text\n","data = pd.read_csv('2013_Paper1 - MCQS.csv')\n","data = data.head(5)\n","\n","def latex_to_text(i):\n","    data.loc[i, 'Question'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Question'])\n","    data.loc[i, 'Option1'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option1'])\n","    data.loc[i, 'Option2'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option2'])\n","    data.loc[i, 'Option3'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option3'])\n","    data.loc[i, 'Option4'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option4'])\n","\n","def predict(i):\n","    try:\n","        query_template.format(Option_1=data.loc[i, 'Option1'], Option_2=data.loc[i, 'Option2'], Option_3=data.loc[i, 'Option3'], Option_4=data.loc[i, 'Option4'], Question=data.loc[i, 'Question'])\n","        result = agent.invoke(query_template)\n","    except:\n","        return 'Error'\n","    else:\n","        return result['output']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHtVG07Wl5m1","outputId":"0f58701c-aab5-41e5-b06b-f794f3b99522"},"outputs":[{"name":"stdout","output_type":"stream","text":["Agent stopped due to iteration limit or time limit.\n","Error\n","625/4\n","2\n","2\n","4\n","4\n","Agent stopped due to iteration limit or time limit.\n","Error\n","null\n","Error\n","2\n","2\n","Error\n","Error\n","Agent stopped due to iteration limit or time limit.\n","Agent stopped due to iteration limit or time limit.\n","4\n","4\n","0\n"]}],"source":["# Implementing self-consistency with CoT\n","from statistics import mode\n","\n","def evaluate(pred, score, i):\n","    if pred == 1:\n","        if data['Answer1'][i] == 1:\n","            score+=1\n","    elif pred == 2:\n","        if data['Answer2'][i] == 1:\n","            score+=1\n","    elif pred == 3:\n","        if data['Answer3'][i] == 1:\n","            score+=1\n","    elif pred == 4:\n","        if data['Answer4'][i] == 1:\n","            score+=1\n","    return score\n","\n","def solve(i):\n","    pred = predict(i)\n","    print(pred)\n","    while(pred == 'Error' or len(pred) > 1):\n","        pred = predict(i)\n","        print(pred)\n","    pred = int(pred)\n","    print(pred)\n","    return pred\n","\n","score = 0\n","for i in range(1): # 1 should be replaced with len(data)\n","    latex_to_text(i)\n","    responses = []\n","    for iter in range(4):\n","        responses.append(solve(i))\n","    final_pred = mode(responses)\n","    score = evaluate(final_pred, score, i)\n","print(score)\n","\n"]},{"cell_type":"markdown","source":["### TESTING THE PIPELINE WITH A DATASET OF QUESTIONS. PIPELINE HAS SOME CHANGES w.r.t. the format of result"],"metadata":{"id":"9caOwQb_l9NE"}},{"cell_type":"code","source":["# Install important libraries\n","!pip install langchain\n","!pip install openai\n","!pip install pylatexenc\n","!pip install langchain_experimental\n","!pip install sentence_transformers\n","!pip install chromadb\n","!pip install wolframalpha\n","from google.colab import userdata\n","OpenAIkey = userdata.get('OpenAIkey')\n","WolframAlphaKey = userdata.get('WolframAlphaKey')"],"metadata":{"id":"IbOg6nUMmrLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6ygOiryl5m2"},"outputs":[],"source":["import langchain\n","import openai\n","\n","# from langchain_google_genai import ChatGoogleGenerativeAI\n","# from sec import GeminiKey\n","# llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GeminiKey)\n","\n","key = OpenAIkey\n","\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","llm = AzureChatOpenAI(azure_endpoint= 'https://amazebotopenai.openai.azure.com/', api_key = key, deployment_name= 'Chat', api_version='2023-05-15')"]},{"cell_type":"code","source":["query_template = '''Solve this question:\n","{Question}\\n and return the correct option number\\n\n","(1) {Option_1}\\n\n","(2) {Option_2}\\n\n","(3) {Option_3}\\n\n","(4) {Option_4}\\n\n","Output the correct option number (1, 2, 3, or 4). I want the output to not exceed length 1.\n","A quick tip: Use wolfram-alpha tool provided to solve math questions. This tool is good for math.\n","Use retrieval_tool to extract context from knowledge base.\n","Let's think step-by-step to reach the final answer.'''\n","\n","query_template = PromptTemplate(\n","    input_variables=[\"Question\", \"Option_1\", \"Option_2\", \"Option_3\", \"Option_4\"],\n","    template=query_template\n",")\n","\n","chain = LLMChain(llm=llm, prompt=query_template, output_key=\"correct_option\")"],"metadata":{"id":"m05QSUZcmRkW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n","from langchain_experimental.utilities import PythonREPL\n","from langchain_experimental.pal_chain import PALChain\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.environ[\"WOLFRAM_ALPHA_APPID\"] = WolframAlphaKey\n","\n","python_repl = PythonREPL()\n","pal_chain = PALChain.from_math_prompt(llm=llm)\n","embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","persist_directory = '/content/drive/My Drive/Colab Notebooks/Langchain/docs/chroma/'\n","vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectordb.as_retriever(),\n",")\n","\n","python_repl = Tool(\n","    name=\"python_repl\",\n","    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n","    func=python_repl.run, handle_parsing_errors=True\n",")\n","\n","pal_math = Tool(\n","    name=\"pal_math\",\n","    description=\"A LLM Chain which helps to solve word problems.\",\n","    func=pal_chain.run, handle_parsing_errors=True\n",")\n","\n","retrieval_tool = Tool(\n","    name='RetrievalQA',\n","    description = 'This tool can be used to get context from the knowledge base of textbooks.',\n","    func=qa_chain.run, handle_parsing_errors=True\n",")\n","\n","tools = load_tools(['llm-math', 'wolfram-alpha'], llm=llm)\n","tools.append(python_repl)\n","tools.append(pal_math)\n","tools.append(retrieval_tool)\n","\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True)\n","# agent.run(\"Given equations for variable x, y, and z: x = y + 5, y = z - 3,  z = x * y. Solve for x, y, z.\")\n","# agent({question:\"Use 'retrieval_tool' to answer the following - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?\"})\n","# agent.run(\"Use 'retrieval_tool' to answer the following - The measured temperature on the Fahrenheit scale is 200 °F. What would the reading be on the Celsius scale?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vg7yjG8mVRG","executionInfo":{"status":"ok","timestamp":1703321086407,"user_tz":-330,"elapsed":10556,"user":{"displayName":"DAKSH","userId":"14266475505689423630"}},"outputId":"e0105ff0-0328-4f3d-aefa-eb491f7bc91c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from pylatexenc.latex2text import LatexNodes2Text\n","data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Langchain/2013_Paper1 - MCQS.csv')\n","\n","def latex_to_text(i):\n","    data.loc[i, 'Question'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Question'])\n","    data.loc[i, 'Option1'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option1'])\n","    data.loc[i, 'Option2'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option2'])\n","    data.loc[i, 'Option3'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option3'])\n","    data.loc[i, 'Option4'] = LatexNodes2Text().latex_to_text(data.loc[i, 'Option4'])\n","\n","def predict(i):\n","    try:\n","        query_template.format(Option_1=data.loc[i, 'Option1'], Option_2=data.loc[i, 'Option2'], Option_3=data.loc[i, 'Option3'], Option_4=data.loc[i, 'Option4'], Question=data.loc[i, 'Question'])\n","        result = agent.invoke(query_template)\n","    except:\n","        return 'Error'\n","    else:\n","        return result['output']\n"],"metadata":{"id":"kIhd4v7HmXAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Implementing self-consistency with CoT\n","from statistics import mode\n","\n","def evaluate(pred, score, i):\n","    if pred == 1:\n","        if data['Answer1'][i] == 1:\n","            score+=1\n","    elif pred == 2:\n","        if data['Answer2'][i] == 1:\n","            score+=1\n","    elif pred == 3:\n","        if data['Answer3'][i] == 1:\n","            score+=1\n","    elif pred == 4:\n","        if data['Answer4'][i] == 1:\n","            score+=1\n","    return score\n","\n","def solve(i):\n","    pred = predict(i)\n","    while(pred == 'Error' or len(pred) > 1):\n","        pred = predict(i)\n","    pred = int(pred)\n","    return pred\n","\n","def solve_section(start_row, last_row):\n","    # start_row denotes the row number where the questions for that particular section starts.\n","    # num_of_questions denote the number of questions in the section.\n","    score = 0\n","    i = start_row\n","    while(i <= last_row):\n","        latex_to_text(i)\n","        responses = []\n","        for iter in range(4):\n","            responses.append(solve(i))\n","        final_pred = mode(responses)\n","        score += evaluate(final_pred, score, i)\n","        print(score)\n","        i += 1\n","    return score\n","\n","# In the output below we can see that there are many time we see some Errors. Such errors are ignored and the llm is called again to get the actual answer.\n","# The output as '3' or '2' is the option number selected. Output as 'Option 2' or 'Option_3' or '(3) Option_3' is ignored.\n","# We see the responses we get are [3,3,3,2]. Mode=3 which is the final answer.\n","# Self-Consistency helps to select the correct option."],"metadata":{"id":"vEFazoF03IEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_end_section(section, start_row, last_row_year):\n","    # len(data)-1 is the total number of questions\n","    while(start_row < last_row_year and data['Subject'][start_row] == section):\n","        start_row+=1\n","    return start_row-1\n","\n","def find_end_year(year, start_row):\n","    while(start_row < len(data) and data['Year'][start_row] == year):\n","        start_row+=1\n","    return start_row-1\n","\n","result= []\n","\n","# Solving an year\n","start_row_year = 0\n","while(start_row_year < len(data)):\n","    year = data['Year'][start_row_year]\n","    last_row_year = find_end_year(year, start_row_year)\n","    # print(start_row_year, last_row_year)\n","    # Solving a section\n","    start_row_section = 0\n","    while(start_row_section < last_row_year):\n","        section=data['Subject'][start_row_section]\n","        last_row_section = find_end_section(section, start_row_section, last_row_year)\n","        print(start_row_section, last_row_section)\n","        score = solve_section(start_row_section, last_row_section)\n","\n","        if(section=='Physics'):\n","            physics_score = score\n","        elif(section == 'Maths'):\n","            math_score = score\n","        elif(section == 'Chemistry'):\n","            chemistry_score = score\n","        print(f'Completed {section} section of year {year}')\n","        start_row_section = last_row_section+1 # Moving to next section\n","\n","    total_num_of_questions = last_row_year-start_row_year+1\n","    # Adding result for an year\n","    result.append(\n","        {\n","        'Year': year,\n","        'Total Questions': total_num_of_questions,\n","        'Correct Questions': score,\n","        'Incorrect Questions': total_num_of_questions-score,\n","        'Physics': physics_score,\n","        'Chemistry': chemistry_score,\n","        'Math': math_score,\n","        'Marks Obtained': score*4\n","        }\n","    )\n","\n","    result = pd.DataFrame(result)\n","    print(result)\n","    result.to_csv('Result.csv', index=False)\n","    start_row_year = last_row_year+1 # Moving to next Year questions"],"metadata":{"id":"vPdDgz5-2h49"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}